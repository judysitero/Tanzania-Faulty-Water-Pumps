{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Tanzania Faulty Water Pumps",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvxi5Mr5oHYZ"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/main/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install pandas-profiling==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9tGB_UA0qBZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# cross validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cfNgDzZoHYa"
      },
      "source": [
        "\n",
        "This project focused on creating and improving a model for the Tanazania Water Pump dataset. The goal was to create a model to predict whether a water pump is functional, non-functional, or needs repair.\n",
        "\n",
        "Dataset source: [DrivenData.org](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are as follows:\n",
        "\n",
        "- **Task 1:** Use `wrangle` function to import training and test data.\n",
        "- **Task 2:** Split training data into feature matrix `X` and target vector `y`.\n",
        "- **Task 3:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 4:** Build `clf_dt`.\n",
        "- **Task 5:** Build `clf_rf`.\n",
        "- **Task 6:** Evaluate classifiers using k-fold cross-validation.\n",
        "- **Task 7:** Tune hyperparameters for best performing classifier.\n",
        "- **Task 8:** Print out best score and params for model.\n",
        "- **Task 9:** Create `submission.csv` and upload to Kaggle.\n",
        "\n",
        "You should limit yourself to the following libraries for this project:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `pandas-profiling`\n",
        "- `sklearn`\n",
        "\n",
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKPWGHayoHYb"
      },
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "    if tv_path:\n",
        "        df = pd.merge(pd.read_csv(fm_path, parse_dates = ['date_recorded'],\n",
        "                                  na_values=[0, -2.000000e-08]),\n",
        "                      pd.read_csv(tv_path)).set_index('id')\n",
        "    else:\n",
        "        df = pd.read_csv(fm_path, parse_dates = ['date_recorded'],\n",
        "                         na_values=[0, -2.000000e-08],\n",
        "                         index_col='id')\n",
        "    \n",
        "\n",
        "    # Drop constant columns\n",
        "    df.drop(columns=['recorded_by'], inplace=True)\n",
        "\n",
        "    # Drop HCCCs\n",
        "    #cutoff = 50\n",
        "    #drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "       #          if df[col].nunique() > cutoff]\n",
        "    #df.drop(columns=drop_cols, inplace=True)\n",
        "    HCCV = [col for col in df.select_dtypes('object') if df[col].nunique() > 50]\n",
        "    df.drop(columns=HCCV, inplace=True)\n",
        "    # Drop duplicate columns\n",
        "    dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
        "                 if df.head(15).T.duplicated()[col]]\n",
        "    df.drop(columns=dupe_cols, inplace=True)         \n",
        "\n",
        "\n",
        "# Feature engineer\n",
        "    #df['water_per_person'] =  df['amount_tsh'] / df['population']   \n",
        "    #Pump Age\n",
        "    df['date_recorded'] = pd.to_datetime(df['date_recorded'], infer_datetime_format=True)\n",
        "\n",
        "    \n",
        "    df['year'] = df['date_recorded'].dt.year\n",
        "    df['month'] = df['date_recorded'].dt.month\n",
        "    df['day'] = df['date_recorded'].dt.day\n",
        "    df = df.drop(columns='date_recorded')\n",
        "    df['pump_age'] = df['year'] - df['construction_year']\n",
        "    df.drop(columns = ['waterpoint_type_group', 'num_private', 'payment_type',\n",
        "                       'payment', 'public_meeting'], inplace= True)\n",
        "    #Water per person\n",
        "    df['water/person'] = df['amount_tsh'] / df['population']\n",
        "     #population per age \n",
        "    #df['pop/year'] = df['population'] / df['pump_age']\n",
        "    #df = df.dropna()\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY4EDnifoHYb"
      },
      "source": [
        "**Task 1:** Used the above `wrangle` function to read `train_features.csv` and `train_labels.csv` into the DataFrame `df`, and `test_features.csv` into the DataFrame `X_test`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFTV-yIjGVSK"
      },
      "source": [
        "train_feature_path = DATA_PATH+'waterpumps/train_features.csv'\n",
        "train_target_path = DATA_PATH+'waterpumps/train_labels.csv'\n",
        "test_feature_path = DATA_PATH+'waterpumps/test_features.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HzutaGaGVs7"
      },
      "source": [
        "df = wrangle(train_feature_path, train_target_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVqonLxMGZTZ"
      },
      "source": [
        "X_test = wrangle(test_feature_path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeXI3wJLoHYc"
      },
      "source": [
        "df = wrangle(DATA_PATH +'waterpumps/train_features.csv', DATA_PATH + 'waterpumps/train_labels.csv' )\n",
        "X_test = wrangle(DATA_PATH +'waterpumps/test_features.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AIRZ0wxvBCj"
      },
      "source": [
        "#Get a series with the cardinality of the nonnumeric features\n",
        "cardinality = df.select_dtypes(exclude='number').nunique()\n",
        "# Get a list of all categorical features with cardinality <= 50\n",
        "low_categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
        "#get a list of high categorical features with cardinality >= 50\n",
        "high_categorical_features = cardinality[cardinality >= 50].index.tolist()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33b7ezW7oHYc"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 2:** Split my DataFrame `df` into a feature matrix `X` and the target vector `y`. I want to predict `'status_group'`.\n",
        "\n",
        "**Note:** I won't need to do a train-test split because you'll use cross-validation instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTgfW9JooHYd"
      },
      "source": [
        "target = 'status_group'\n",
        "X = df.drop(columns=target)\n",
        "y = df[target]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_N58undoHYd"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 3:** Since this is a **classification** problem, I need to  establish a baseline accuracy score. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bc1SfF5oHYd",
        "outputId": "108e573d-38b9-42fc-b6fd-973cb9275179"
      },
      "source": [
        "baseline_acc = baseline_acc = (y.value_counts(normalize=True).max())\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy Score: 0.5430899510092763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml5Jz_ksoHYe"
      },
      "source": [
        "# IV. Build Models\n",
        "\n",
        "**Task 4:** Build a `Pipeline` named `clf_dt`. My `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `DecisionTreeClassifier` Predictor.\n",
        "\n",
        "**Note:** Do not train `clf_dt`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9QBuDC5oHYe"
      },
      "source": [
        "clf_dt = make_pipeline(OrdinalEncoder(),                 \n",
        "                         SimpleImputer(),\n",
        "                         DecisionTreeClassifier (random_state = 200))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rge-oDtL8OuC"
      },
      "source": [
        "#cv_scores_dt = cross_val_score(clf_dt, X_train, y_train, cv=3, scoring = 'accuracy')\n",
        "#print(cv_scores_dt)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DkwaDr0oHYf"
      },
      "source": [
        "**Task 5:** Build a `Pipeline` named `clf_rf`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `RandomForestClassifier` predictor.\n",
        "\n",
        "**Note:** Do not train `clf_rf`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRrJuAlQoHYf"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.feature_selection import f_regression, SelectKBest\n",
        "\n",
        "\n",
        "clf_rf = make_pipeline(OrdinalEncoder(),                 \n",
        "                         SimpleImputer(),\n",
        "                         RandomForestClassifier(n_estimators = 300, criterion='gini',min_samples_split = 4,\n",
        "                                                min_samples_leaf = 3,\n",
        "                                                max_depth = 25, random_state = 200 , n_jobs = -1))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lBSSsda7B0t"
      },
      "source": [
        "#cv_scores_rf = cross_val_score(clf_rf, X_train, y_train, cv=3, scoring = 'accuracy')\n",
        "#print(cv_scores_rf)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVZRBMSjoHYf"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "**Task 6:** Evaluate the performance of both of your classifiers using k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QThYX8CSiEO"
      },
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WZVvzC3oHYg"
      },
      "source": [
        "#from sklearn import tree\n",
        "#from sklearn.cross_validation import cross_val_score\n",
        "#from pprint import pprint\n",
        "cv_scores_dt = cross_val_score(clf_dt, X, y, cv=3, scoring = 'accuracy')\n",
        "cv_scores_rf = cross_val_score(clf_rf, X, y, cv=3, scoring = 'accuracy')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSq1BdtUoHYg",
        "outputId": "0f29ebfa-206b-44aa-b3ba-5d93ebf56abe"
      },
      "source": [
        "print('CV scores DecisionTreeClassifier')\n",
        "print(cv_scores_dt)\n",
        "print('Mean CV accuracy score:', cv_scores_dt.mean())\n",
        "print('STD CV accuracy score:', cv_scores_dt.std())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV scores DecisionTreeClassifier\n",
            "[0.75035354 0.7480303  0.74306783]\n",
            "Mean CV accuracy score: 0.7471505566975035\n",
            "STD CV accuracy score: 0.003038731600273231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aVD38T5oHYg",
        "outputId": "2e8ae7b9-79b6-41f1-ce95-807cfae3ce87"
      },
      "source": [
        "print('CV score RandomForestClassifier')\n",
        "print(cv_scores_rf)\n",
        "print('Mean CV accuracy score:', cv_scores_rf.mean())\n",
        "print('STD CV accuracy score:', cv_scores_rf.std())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score RandomForestClassifier\n",
            "[0.80338384 0.80762626 0.80246477]\n",
            "Mean CV accuracy score: 0.8044916239860429\n",
            "STD CV accuracy score: 0.002248057056135457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLOhW_5poHYh"
      },
      "source": [
        "# VI. Tune Model\n",
        "\n",
        "**Task 7:** Choose the best performing of my two models and tune its hyperparameters using a `RandomizedSearchCV` named `model`. Include cross-validation and that `n_iter` is set to at least `25`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY-_pyQT_0Vi"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl0nHnmbDHwm"
      },
      "source": [
        "max_depth = [10, 30, 25] # 3 choices\n",
        "n_estimators = range(300, 250, 400) # 5 choices\n",
        "min_sample_split = range(2,4, 2) # 4 choices\n",
        "criterion = ['gini', 'entropy'] # 2 choices\n",
        "min_samples_leaf = [3, 2, 4, 5]\n",
        "\n",
        "param_grid = {\n",
        "    'simpleimputer__strategy': ['mean', 'median', 'most_frequent'], \n",
        "    'randomforestclassifier__max_depth': [10, 30, 50],\n",
        "    'randomforestclassifier__n_estimators': range(150, 300, 400),\n",
        "    'randomforestclassifier__min_samples_split': range(5, 21, 5),\n",
        "    'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
        "    'randomforestclassifier__min_samples_leaf': [3,2,4, 5]}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yiLpGw-hBpO"
      },
      "source": [
        "#model_gs = GridSearchCV(clf_rf, param_grid=param_grid, n_jobs = -1, cv=3,  verbose=10)\n",
        "#model_gs.fit(X, y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lAD8jbpoHYh",
        "outputId": "e4ce9575-0b82-4d44-d4ae-aeb67f861b2c"
      },
      "source": [
        "model = RandomizedSearchCV(\n",
        "    clf_rf, \n",
        "    param_distributions=param_grid, \n",
        "    n_iter=25, \n",
        "    cv=5,  \n",
        "    n_jobs=-1,\n",
        "    verbose=10)\n",
        "\n",
        "model.fit(X, y)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[('ordinalencoder',\n",
              "                                              OrdinalEncoder()),\n",
              "                                             ('simpleimputer', SimpleImputer()),\n",
              "                                             ('randomforestclassifier',\n",
              "                                              RandomForestClassifier(max_depth=25,\n",
              "                                                                     min_samples_leaf=3,\n",
              "                                                                     min_samples_split=4,\n",
              "                                                                     n_estimators=300,\n",
              "                                                                     n_jobs=-1,\n",
              "                                                                     random_state=200))]),\n",
              "                   n_iter=25, n_jobs=-1,\n",
              "                   param_distributions={'randomforestclassifier__criterion': ['gini',\n",
              "                                                                              'entropy'],\n",
              "                                        'randomforestclassifier__max_depth': [10,\n",
              "                                                                              30,\n",
              "                                                                              50],\n",
              "                                        'randomforestclassifier__min_samples_leaf': [3,\n",
              "                                                                                     2,\n",
              "                                                                                     4,\n",
              "                                                                                     5],\n",
              "                                        'randomforestclassifier__min_samples_split': range(5, 21, 5),\n",
              "                                        'randomforestclassifier__n_estimators': range(150, 300, 400),\n",
              "                                        'simpleimputer__strategy': ['mean',\n",
              "                                                                    'median',\n",
              "                                                                    'most_frequent']},\n",
              "                   verbose=10)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSoGw-xMoHYh"
      },
      "source": [
        "**Task 8:** Print out the best score and best params for `model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XObN_xqZoHYi",
        "outputId": "bbcb9dd8-e3f4-4c75-c293-0dee80729743"
      },
      "source": [
        "best_score = model.best_score_\n",
        "best_params = model.best_params_\n",
        "\n",
        "print('Best score for `model`:', best_score)\n",
        "print('Best params for `model`:', best_params)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score for `model`: 0.8094917111740918\n",
            "Best params for `model`: {'simpleimputer__strategy': 'mean', 'randomforestclassifier__n_estimators': 150, 'randomforestclassifier__min_samples_split': 10, 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__max_depth': 30, 'randomforestclassifier__criterion': 'entropy'}\n"
          ]
        }
      ]
    }
  ]
}